{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf3d23f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9680b549c4293dcfc584779b0565b175",
     "grade": false,
     "grade_id": "cell-49b24469f46dfeca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Inverse Problems Exercises: 2022s s03 (non-physics)\n",
    "https://www.umm.uni-heidelberg.de/miism/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d1fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "179f33519e873e1cda11f614f26fd437",
     "grade": false,
     "grade_id": "cell-e0e89221bb2eb391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Notes\n",
    "* Please **DO NOT** change the name of the `.ipynb` file. \n",
    "* Please **DO NOT** import extra packages to solve the tasks. \n",
    "* Please put the `.ipynb` file directly into the `.zip` archive without any intermediate folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6444af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "577de3d815a5433df6d24b2edf6f4512",
     "grade": false,
     "grade_id": "cell-25297d00d0806932",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Please provide your personal information\n",
    "* full name (Name): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad1b85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed66fd19bab168d80c4865c274aecd5",
     "grade": true,
     "grade_id": "cell-2d2bf14a246580e7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Maximilian Richter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73002e5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "254537f6f7b15a0daf85510ba1c27bb3",
     "grade": false,
     "grade_id": "cell-f1875ccbf1bb47f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## D01b: Wiener filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5996d2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb916482ba73a2365a5fcdcdf5623993",
     "grade": false,
     "grade_id": "cell-57c6389240bb6a65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55769ad7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06a201454bbdfc8bc1ad27d0060b97a3",
     "grade": false,
     "grade_id": "cell-646a09da75f9c3a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "file_gaussian = 'file_gaussian.npz'\n",
    "\n",
    "with np.load(file_gaussian) as data:\n",
    "    f_true = data['f_true']\n",
    "    h_psf = data['h_psf']\n",
    "    list_gn = data['list_gn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab44b1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bda8b207cef346ab9cd6d357e475014f",
     "grade": false,
     "grade_id": "cell-bce47ff5b06b5f04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Imaging model\n",
    "The imaging model can be represented by\n",
    "$$\n",
    "g = h \\otimes f_\\text{true}\n",
    "= Af_\\text{true}\n",
    "= \\mathcal{F}^{-1}\\{ \\mathcal{F}\\{h\\} \\mathcal{F}\\{f_\\text{true}\\} \\},\n",
    "$$\n",
    "$$\n",
    "g' = g + \\epsilon.\n",
    "$$\n",
    "* $f_\\text{true}$ is the input signal\n",
    "* $h$ is the point spread function (kernel)\n",
    "* $\\otimes$ is the convolution operator\n",
    "* $A$ is the Toeplitz matrix of $h$\n",
    "* $\\mathcal{F}$ and $\\mathcal{F}^{-1}$ are the Fourier transform operator and inverse Fourier transform operator\n",
    "* $\\epsilon$ is the additive Gaussian noise\n",
    "* $g$ is the filtered signal\n",
    "* $g'$ is the noisy signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc2c08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dd66d7bc9196aa0e1814dd718a95bdf",
     "grade": false,
     "grade_id": "cell-8071a22374dbd8af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fourier transform of the kernel\n",
    "Implement the Fourier transform of the kernel $\\mathcal{F}\\{h\\}$\n",
    "* Given the kernel $h$\n",
    "* Given the length of the transformed kernel $l$\n",
    "* Pad zeros to both sides of the kernel\n",
    "* Adjust the kernels as long as $l$\n",
    "* Shift the origin of the kernels to the first element of the array\n",
    "* Apply the Fourier transform to the shifted padded kernel (using `numpy.fft.fft()`)\n",
    "* Implement the function `fft_kernel()` (using `numpy.array`)\n",
    "\n",
    "Calculate the transformed kernel\n",
    "* Apply the transform to `h_psf`\n",
    "* Return the outputs of with the length of $100$, $1000$, $10000$, respectively\n",
    "* Save the outputs in the variable `list_h_fft` (as `list` of `numpy.array`)\n",
    "\n",
    "Display the result\n",
    "* Plot the absolute value of the outputs in `list_h_fft` in the same order of the parameter options in the subplots of `axs`\n",
    "* Plot the outputs properly in the frequency domain\n",
    "* Plot the outputs with the marker \"+\"\n",
    "* Add proper titles to the subplots of `axs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f1ec8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8e6eb31317272d6e10f61294610e051",
     "grade": false,
     "grade_id": "cell-bdd66d3021fa85e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fft_kernel(kernel, length):\n",
    "    \"\"\"Compute the discrete Fourier Transform of the kernel.\n",
    "\n",
    "    :param kernel: 1d kernel of the system\n",
    "    :param length: length of the transformed kernel\n",
    "    :returns: Transformed kernel\n",
    "    \"\"\"\n",
    "    padded = np.pad(kernel, int(length/2-kernel.shape[0]/2+1))\n",
    "    shifted = np.roll(padded[1:], int(padded.shape[0]/2+1))\n",
    "    return np.fft.fft(shifted)\n",
    "\n",
    "lengths = [100, 1000, 10000]\n",
    "list_h_fft = [fft_kernel(h_psf, n) for n in lengths]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10))\n",
    "fig.suptitle('Fourier transform')\n",
    "\n",
    "for i in range(len(list_h_fft)):\n",
    "    axs[i].plot(np.abs(list_h_fft[i]), \"+\")\n",
    "    axs[i].set_title(\"Length of {}\".format(lengths[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52c733",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bb600323323050db9b33cf5a2179801",
     "grade": true,
     "grade_id": "a010",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841ec45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1baebacf27f7ec8062e56282f5574280",
     "grade": true,
     "grade_id": "a020",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf3b1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "376b47732c73cfa5a3b08a7023495379",
     "grade": false,
     "grade_id": "cell-d1e128ec57cbea96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Mean squared error\n",
    "Implement the mean squared error (MSE)\n",
    "$$\n",
    "\\operatorname{MSE}(\\tilde f)=\\frac{1}{n}\\sum_{i=1}^n(f_{\\text{true}i}-\\tilde f_i)^2\n",
    "$$\n",
    "* Given the true signal $f_\\text{true}$\n",
    "* Given the estimate $\\tilde f$\n",
    "* Implement the function `mean_squared_error()` (using `numpy.array`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132155b3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fcd11fc0572291aae9b8ec28ca7197a",
     "grade": false,
     "grade_id": "cell-fdf68a6db270b31b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(f_true, f_est):\n",
    "    \"\"\" Compute the mean squared error comparing to the true signal:\n",
    "\n",
    "    :param f_true: True signal.\n",
    "    :param f_est: Estimate of the signal.\n",
    "    :returns: Mean squared error.\n",
    "    \"\"\"\n",
    "    return np.mean((f_true - f_est)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa9db7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f70b08d43eaa1febab08e29498daa515",
     "grade": true,
     "grade_id": "a030",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1383aa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "307028bc6ee47c200956f3b4267171c8",
     "grade": false,
     "grade_id": "cell-a8322192a882c8e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Inverse filter\n",
    "Implement the inverse filter\n",
    "$$\n",
    "\\tilde{f} = \\mathcal{F}^{-1}\\{ \\frac{1}{\\mathcal{F}\\{h\\} + s^2} \\cdot \\mathcal{F}\\{g'\\} \\}\n",
    "$$\n",
    "* Given the kernel $h$\n",
    "* Given the noisy signal $g'$\n",
    "* Given the small positive parameter $s^2$\n",
    "* Transform the kernel by `fft_kernel()`\n",
    "* Implement the function `inverse_filter()` (using `numpy.array`)\n",
    "\n",
    "Apply the inverse filter\n",
    "* Apply the inverse filter to the noisy signals in `list_gn`\n",
    "* Return the outputs with $s^2$ of $0.5$, $0.1$, $0.02$, respectively \n",
    "* Save the outputs in the variable `list_f_inv` (as `list` of `numpy.array`)\n",
    "\n",
    "Display the result\n",
    "* Plot the outputs in `list_f_inv` in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplot column\n",
    "* Show the cases with the same $s^2$ in the same subplot row\n",
    "* Plot the corresponding noisy signal in each subplot\n",
    "* Plot the input signal `f_true` in each subplot\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aa94b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab03e36167a56a08239af6a5676f2dd3",
     "grade": true,
     "grade_id": "a035",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def inverse_filter(kernel, signal, s_sqr):\n",
    "    \"\"\"Apply an inverse filter kernel to a signal to deblur it.\n",
    "    Use a small positive parameter s_sqr to avoid division by zero.\n",
    "\n",
    "    :param kernel: 1d kernel of the system\n",
    "    :param signal: 1d signal, which should be filtered\n",
    "    :param s_sqr: Small positive parameter\n",
    "    :returns: Filtered signal\n",
    "    \"\"\"\n",
    "    return np.fft.ifft(np.fft.fft(signal) / (fft_kernel(kernel, signal.shape[0]) + s_sqr))\n",
    "\n",
    "list_f_inv = []\n",
    "s_sqr = [0.5, 0.1, 0.02]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        list_f_inv.append(inverse_filter(h_psf, list_gn[j], s_sqr[i]))\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Inverse filter')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        gn = list_gn[j]\n",
    "        f_est = list_f_inv[i*3+j].real\n",
    "        mse = mean_squared_error(f_true, f_est)\n",
    "        axs[i,j].plot(f_true, label=\"$f_{true}$\", color=\"black\")\n",
    "        axs[i,j].plot(gn, label=\"$g$\", color=\"blue\", alpha=0.8)\n",
    "        axs[i,j].plot(f_est, label=\"Inverse\", color=\"darkorange\", alpha=0.8)\n",
    "        axs[i,j].set_title(\"Signal {}, $s^2$ = {}, MSE = {}\".format(j, s_sqr[i], np.round(mse)))\n",
    "        axs[i,j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0c0b48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0268730dab168f3e23efbddd387e8ec7",
     "grade": true,
     "grade_id": "a045",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ab39b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e5f3b774f67912b23e163ba8e39bc23",
     "grade": true,
     "grade_id": "a055",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c1efa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5180d6326878bbcf9d727d7586204463",
     "grade": false,
     "grade_id": "cell-544046a9bb51fcfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Describe the influence of $s^2$ on the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559fdf8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61dfc924f17d99bca526830adb6cb996",
     "grade": true,
     "grade_id": "a065",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The results of this experiment suggests that the size of $s^2$ has a vast influence on the reconstruction of the signal by means of a inverse filter. This means in particular that both, very small and very big numbers for $s^2$ result in a similar high MSE. What differs is the source of these high errors. In the case of a big $s^2$ (0.5) the reconstructed signal is lower in amplitude than the original signal. This is due to the additional bias ontop of the theoretical inverse of the convolution. In the case of small $s^2$ (0.02), the division of small numbers result in a over amplified noise. Only for a \"golden middle\" $s^2$ of 0.1, the signal is not pushed down and the resulting noise is moderate. This means that $s^2$ has to be chosen by trading-off bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e5bfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ef1fcf44b829460fd6a6e95888371c0",
     "grade": false,
     "grade_id": "cell-468c8206e2c832c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Wiener filter\n",
    "Implement the Wiener filter\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{f} &= \\mathcal{F}^{-1}\\{ W \\cdot \\mathcal{F}\\{g'\\} \\} \\\\\n",
    " &= \\mathcal{F}^{-1}\\{ \\frac{\\mathcal{F}\\{h\\}^*}{|\\mathcal{F}\\{h\\}|^2 + \\text{NSR}} \\cdot \\mathcal{F}\\{g'\\} \\} \\\\\n",
    " &= \\mathcal{F}^{-1}\\{ \\frac{1}{\\mathcal{F}\\{h\\}} \\cdot \\frac{|\\mathcal{F}\\{h\\}|^2}{|\\mathcal{F}\\{h\\}|^2 + \\text{NSR}} \\cdot \\mathcal{F}\\{g'\\} \\} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "* Given the kernel $h$\n",
    "* Given the noisy signal $g'$\n",
    "* Given the small positive parameter $\\text{NSR}$\n",
    "* Transform the kernel by `fft_kernel()`\n",
    "* Implement the function `wiener_filter()` (using `numpy.array`)\n",
    "\n",
    "Apply the Wiener filter\n",
    "* Apply the Wiener filter to the noisy signals in `list_gn`\n",
    "* Return the outputs with $\\text{NSR}$ of $0.1$, $0.01$, $0.001$, respectively \n",
    "* Save the outputs in the variable `list_f_wiener` (as `list` of `numpy.array`)\n",
    "\n",
    "Display the result\n",
    "* Plot the outputs in `list_f_wiener` in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplot column\n",
    "* Show the cases with the same $\\text{NSR}$ in the same subplot row\n",
    "* Plot the corresponding noisy signal in each subplot\n",
    "* Plot the input signal `f_true` in each subplot\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "\n",
    "See\n",
    "* https://en.wikipedia.org/wiki/Wiener_deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47494c2a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be1f73014c44e73d3880396814d0591d",
     "grade": true,
     "grade_id": "a070",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def wiener_filter(kernel, signal, nsr):\n",
    "    \"\"\"Apply a wiener filer on the signal to deblur and denoise it.\n",
    "\n",
    "    :param kernel: 1d kernel of the system\n",
    "    :param signal: 1d blurred signal with noise\n",
    "    :param nsr: Noise-to-signal ratio of the noise to the original signal\n",
    "    :returns: Deblured and denoised signal\n",
    "    \"\"\"\n",
    "    F_h = fft_kernel(kernel, signal.shape[0])\n",
    "    abs_F_h_sqrd = np.abs(F_h)**2\n",
    "    return np.fft.ifft(np.fft.fft(signal) * abs_F_h_sqrd / (F_h*(abs_F_h_sqrd + nsr)))\n",
    "\n",
    "\n",
    "list_f_wiener = []\n",
    "nsr = [0.1, 0.01, 0.001]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        list_f_wiener.append(wiener_filter(h_psf, list_gn[j], nsr[i]))\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Wiener filter')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        gn = list_gn[j]\n",
    "        f_est = list_f_wiener[i*3+j].real\n",
    "        mse = mean_squared_error(f_true, f_est)\n",
    "        axs[i,j].plot(f_true, label=\"$f_{true}$\", color=\"black\")\n",
    "        axs[i,j].plot(gn, label=\"$g$\", color=\"blue\", alpha=0.7)\n",
    "        axs[i,j].plot(f_est, label=\"Wiener\", color=\"darkorange\")\n",
    "        axs[i,j].set_title(\"Signal {}, NSR = {}, MSE = {}\".format(j, nsr[i], np.round(mse)))\n",
    "        axs[i,j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033687d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e45354138c8c07746fc1cbb316eb99",
     "grade": true,
     "grade_id": "a080",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6fc1e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8774e75ea2d4b29915c36240ad92936",
     "grade": true,
     "grade_id": "a090",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f25132",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41c3fa5a7b37ba8c9470e948ea82182c",
     "grade": false,
     "grade_id": "cell-bede8b380b9a796c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare the results using the Wiener filter to the ones using the inverse filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3c960",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "195b7079323a714b674fda7b242fa684",
     "grade": true,
     "grade_id": "a100",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The Wiener filter performs significantly different in all cases than the plain inverse filter. This can be seen for example by comparing the MSE, which is lower (and therefore better) for all cases. The Wiener filter seems to change slower for different values for the NSR, i.e. the interval with the optimal NSR value is larger than in the case of the inverse filter. \n",
    "The Wiener filter is also more robust against noise in the filtered data. While the inverse filter struggles enormously, the Wiener filter is still able to make a decent reconstruction.\n",
    "In summary, the wiener-filter inverts the convolution with the Gaussian PSF as good or even better than the inverse filter, and is furthermore less prone to bad choices of the additional bias and robust against noise. While the inverse filter is reconstructing the signal before the convolution very well for the right choice of $s^2$, it can result in useless noise if too small or too high. This makes the wiener filter better in practice, when this is a problem and a little more computational effort is acceptable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75531c",
   "metadata": {},
   "source": [
    "# Additional Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16356cd7",
   "metadata": {},
   "source": [
    "While the exercise was really nice and educational, it was rather confusing that the source of the signal was not known. I think it would be much more illustrative if the model for the data creation would be included in the code, so that we really understand the aim of inverse filtering. Reasons for which i think this would benefit the understanding is that i did not realize until the end of this exercise that we have to \"reconstruct the noise\" (so to say). I first thought (intuitively) that the less noisy reconstruction is the better one, while in deconvoluting a Gaussian kernel the aim is to regain the sharp edges. As an example i have programmed myself this little example in which the differences of the Inverse and Wiener Filter get quite clear (at least in my opinion). Here it seems also, that the inverse filter is doing a better job at deconvoluting the signal, in contrary to the examples above.  Anyways, have fun correcting the exercises :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81804a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = np.linspace(0,10,100)\n",
    "data = np.sin(lin)+np.random.normal(0,0.5,lin.shape[0])\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(data, label=\"True Data\", color=\"black\")\n",
    "plt.plot(np.convolve(data, h_psf, mode=\"same\"), label=\"Filtered Signal\")\n",
    "plt.plot(inverse_filter(h_psf, data, 0.5).real, label=\"Inverse Filter\")\n",
    "plt.plot(wiener_filter(h_psf, data, 0.01).real, label=\"Wiener Filter\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0f1a6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efcf8a7d29568ee6aa19d18162f3216c75d115c7ce0b1cb4e80848b9a37f2ca8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
