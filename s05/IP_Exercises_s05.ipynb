{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf3d23f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "599a85c2206909f386c59e7b01f64277",
     "grade": false,
     "grade_id": "cell-49b24469f46dfeca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Inverse Problems Exercises: 2022s s05 (non-physics)\n",
    "https://www.umm.uni-heidelberg.de/miism/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30cb0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cec4cf272782838191548438284b86fc",
     "grade": false,
     "grade_id": "cell-fa7322d20795c385",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Notes\n",
    "* Please **DO NOT** change the name of the `.ipynb` file. \n",
    "* Please **DO NOT** import extra packages to solve the tasks. \n",
    "* Please put the `.ipynb` file directly into the `.zip` archive without any intermediate folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6444af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "577de3d815a5433df6d24b2edf6f4512",
     "grade": false,
     "grade_id": "cell-25297d00d0806932",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Please provide your personal information\n",
    "* full name (Name): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad1b85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed66fd19bab168d80c4865c274aecd5",
     "grade": true,
     "grade_id": "cell-2d2bf14a246580e7",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Maximilian Richter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73002e5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "353281faf4195506142af09abb25718f",
     "grade": false,
     "grade_id": "cell-f1875ccbf1bb47f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## D04c: Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c35d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81f7a1be0fbc28394bec7a9ffcf0acf8",
     "grade": false,
     "grade_id": "cell-83d8e161fbf2ff18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import fminbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c4676",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f83e47a5bacb52c9c792c2e6348922a",
     "grade": false,
     "grade_id": "cell-d97f18da42991fc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "file_gaussian = 'file_gaussian.npz'\n",
    "with np.load(file_gaussian) as data:\n",
    "    f_true = data['f_true']\n",
    "    A_psf = data['A_psf']\n",
    "    list_gn = data['list_gn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7a6da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27a4cb1c581c051eacf4c52176df4113",
     "grade": false,
     "grade_id": "cell-86e480e83faad2c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Imaging model\n",
    "The imaging model can be represented by\n",
    "$$\n",
    "g = h \\otimes f_\\text{true}\n",
    "= Af_\\text{true}\n",
    "= \\mathcal{F}^{-1}\\{ \\mathcal{F}\\{h\\} \\mathcal{F}\\{f_\\text{true}\\} \\},\n",
    "$$\n",
    "$$\n",
    "g' = g + \\epsilon.\n",
    "$$\n",
    "* $f_\\text{true}$ is the input signal\n",
    "* $h$ is the point spread function (kernel)\n",
    "* $\\otimes$ is the convolution operator\n",
    "* $A$ is the Toeplitz matrix of $h$\n",
    "* $\\mathcal{F}$ and $\\mathcal{F}^{-1}$ are the Fourier transform operator and inverse Fourier transform operator\n",
    "* $\\epsilon$ is the additive Gaussian noise\n",
    "* $g$ is the filtered signal\n",
    "* $g'$ is the noisy signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b569ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1587873f207ede6d6506f6c323ad06e",
     "grade": false,
     "grade_id": "cell-47eec6821784b19a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Mean squared error\n",
    "Implement the mean squared error (MSE)\n",
    "$$\n",
    "\\operatorname{MSE}(f)=\\frac{1}{n}\\sum_{i=1}^n(f_i - f_{\\text{true}i})^2\n",
    "$$\n",
    "* Given the input signal $f$\n",
    "* Given the true signal $f_\\text{true}$\n",
    "* Implement the function `mean_squared_error()` (using `numpy.array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b49a64",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "131aabf4a35abbe41418bf9d7b05dfab",
     "grade": false,
     "grade_id": "cell-1c1d2c46bf0b94fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(f, f_true):\n",
    "    \"\"\" Compute the mean squared error comparing to the true signal:\n",
    "\n",
    "    :param f: Input signal.\n",
    "    :param f_true: True signal.\n",
    "    :returns: Mean squared error.\n",
    "    \"\"\"\n",
    "    return np.mean((f - f_true)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98caae93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78f47b6ec4b90861355c1b30b9b62b76",
     "grade": true,
     "grade_id": "a001",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bb2ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e17732fa7e132a58cd27296e0d495b71",
     "grade": false,
     "grade_id": "cell-6e24b51519ca0298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Difference matrix\n",
    "Implement the difference matrix $D_\\text{diff}$\n",
    "$$D_\\text{diff} = \\begin{bmatrix} \n",
    "1 & 0 & 0 & 0 & ... & 0 & -1 \\\\\n",
    "-1 & 1 & 0 & 0 & ... & 0 & 0 \\\\\n",
    "0 & -1 & 1 & 0 & ... & 0 & 0 \\\\\n",
    "  &   &   & ... &   &   & \\\\\n",
    "0 & 0 & 0 & 0 & ... & -1 & 1 \\end{bmatrix}$$\n",
    "* Given the size $n_\\text{diff}$\n",
    "* Implement the function `get_diff_matrix()` (using `numpy.array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae95f9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bdc62b99073247eb635f659b9155893",
     "grade": false,
     "grade_id": "cell-dd13efdc2eeb3c3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_diff_matrix(n):\n",
    "    \"\"\" Compute a matrix to calculate the difference along a vector of the size n\n",
    "    between two neighboring elements.\n",
    "\n",
    "    :param n: Size of the target vector.\n",
    "    :returns: Matrix with shape (n, n), which calculates the difference.\n",
    "    \"\"\"\n",
    "    diff_matrix = np.eye(n)\n",
    "    diff_matrix[1:,:-1] += np.eye(n-1)*-1\n",
    "    diff_matrix[0,n-1] = -1\n",
    "    return diff_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afb928",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1bb2105c90bc37972994b74ceb0d8c1",
     "grade": true,
     "grade_id": "a002",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e51a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06dd0cc33a40fe2dc7bc9980ee416645",
     "grade": false,
     "grade_id": "cell-eb429033d3c3ba18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tikhonov regularization\n",
    "Implement the objective function with Tikhonov regularization\n",
    "$$\n",
    "L(f) = \\|Af - g'\\|_2^2 + \\lambda\\|D'f\\|_2^2\n",
    "$$\n",
    "* Given the input signal $f$\n",
    "* Given the system matrix $A$\n",
    "* Given the measurement $g'$\n",
    "* Given the regularization matrix $D'$\n",
    "* Given the regularization parameter $\\lambda$\n",
    "* Implement the function `objective_tikhonov()` (using `numpy.array`)\n",
    "\n",
    "Implement the closed form solution of the regularized objective function\n",
    "$$\n",
    "\\tilde f = (A^T A + \\lambda D'^T D')^{-1} A^T g' = A_\\lambda^{PI} g'\n",
    "$$\n",
    "* Given the system matrix $A$\n",
    "* Given the measurement $g'$\n",
    "* Given the regularization matrix $D'$\n",
    "* Given the regularization parameter $\\lambda$\n",
    "* Implement the function `solution_tikhonov()` (using `numpy.array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de31b7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "373da2809360802e29f768d85d44d976",
     "grade": false,
     "grade_id": "cell-30aa06bf0e9b65df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def objective_tikhonov(f, A, g, D, lb):\n",
    "    \"\"\" Compute the objective function with Tikhonov regularization.\n",
    "    \n",
    "    :param f: Current estimate of the signal.\n",
    "    :param A: 2D matrix of the linear problem.\n",
    "    :param g: Observed signal.\n",
    "    :param D: 2D matrix in the regularization term.\n",
    "    :param lb: Regularization parameter.\n",
    "    :returns: Objective function value.\n",
    "    \"\"\"\n",
    "    return np.sum((A@f - g)**2) + lb * np.sum((D@f)**2)\n",
    "\n",
    "\n",
    "def solution_tikhonov(A, g, D, lb):\n",
    "    \"\"\" Compute the estimate of the true signal with Tikhonov regularization.\n",
    "\n",
    "    Use a regularization term to suppress noise.\n",
    "\n",
    "    :param A: 2d matrix A of the linear problem.\n",
    "    :param g: Observed signal.\n",
    "    :param D: 2D matrix in the regularization term.\n",
    "    :param lb: Regularization parameter.\n",
    "    :returns: Estimate of the true signal.\n",
    "    \"\"\"\n",
    "    return np.linalg.inv(A.T @ A + lb * D.T @ D) @ A.T @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca5878a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154b1a34cadb59de9e58a2682230dacc",
     "grade": true,
     "grade_id": "a003",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad8cf1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34199a98aeaf15b750dec60af43466bf",
     "grade": true,
     "grade_id": "a004",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb253c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a26596113e3942782f09af1b7196c8",
     "grade": false,
     "grade_id": "cell-9f4de28d122b2897",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Gradient magnitude solution\n",
    "The gradient magnitude solution is the solution with $D' = D_\\text{diff}$\n",
    "* Calculate the closed form solution for the noisy signals in `list_gn`\n",
    "* Return the outputs with $\\lambda$ of $0.1$, $0.01$, $0.001$, respectively \n",
    "* Save the solutions in the variable `list_f_closed` (as `list` of `numpy.array`)\n",
    "* Save the corresponding objective values in the variable `list_L_closed` (as `list` of scalars)\n",
    "\n",
    "Display the result\n",
    "* Plot the outputs in `list_f_closed` in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplot column\n",
    "* Show the cases with the same $\\lambda$ in the same subplot row\n",
    "* Plot the corresponding noisy signal in each subplot\n",
    "* Plot the input signal `f_true` in each subplot\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "* Show the objective function value of each output in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483c6d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7484c90ab47db78fbba6e0e7882536bf",
     "grade": true,
     "grade_id": "a005",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Gradient magnitude solution (closed form)')\n",
    "\n",
    "lbs = [0.1, 0.01, 0.001]\n",
    "list_f_closed = []\n",
    "list_L_closed = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        f_closed = solution_tikhonov(A_psf, list_gn[j], get_diff_matrix(A_psf.shape[0]), lbs[i])\n",
    "        MSE = np.round(mean_squared_error(f_closed, f_true))\n",
    "        objective = np.round(objective_tikhonov(f_closed, A_psf, list_gn[j], get_diff_matrix(A_psf.shape[0]),lbs[i]))\n",
    "        \n",
    "        list_f_closed.append(f_closed)        \n",
    "        list_L_closed.append(objective)\n",
    "\n",
    "        axs[i,j].plot(f_closed, label=\"$f_{est}$\")\n",
    "        axs[i,j].plot(list_gn[j], label=\"g\")\n",
    "        axs[i,j].plot(f_true, label=\"$f_{true}$\", color=\"black\")\n",
    "        \n",
    "        axs[i,j].set_title(\"$g_{}$, $\\lambda ={}$, $MSE ={}$, $L(f) ={}$\".format(j, lbs[i], MSE, objective))\n",
    "        axs[i,j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a1968",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbb8d271391aeace1aa1d5c16cb4a66f",
     "grade": true,
     "grade_id": "010",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d2cff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "764d86db4afdb836e86faa4d0f8ddbe4",
     "grade": false,
     "grade_id": "cell-544046a9bb51fcfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Gradient descent technique\n",
    "Gradient descent is an optimization method to find an $f$, which minimize the objective function $L(f)$.\n",
    "One iterative update is given by\n",
    "$$\n",
    "f^{(i+1)} = f^{(i)} - s_i \\nabla L(f^{(i)}),\n",
    "$$\n",
    "where $s_i$ is the optimal step size of the one-dimensional optimization problem\n",
    "$$\n",
    "s_i = \\arg\\min_{s\\in \\mathbb{R}^+} L(f^{(i)} - s \\nabla L(f^{(i)})).\n",
    "$$\n",
    "\n",
    "Implement the iterative gradient descent updates\n",
    "* Given the objective function $L(f)$\n",
    "* Given the gradient of the objective function $\\nabla L(f)$\n",
    "* Given the initial value $f^{(0)}$\n",
    "* Given the number of iterations $n$\n",
    "* Estimating the optimal step size $s_i$ in $[0, 10]$ (using ```scipy.optimize.fminbound()```)\n",
    "* Return the final value $f^{(n)}$ as the first output\n",
    "* Return the history array of objective values $[L(f^{(0)}), ..., L(f^{(n)})]$ as the second output\n",
    "* Implement the function `solve_gradient_descent_ls()` (using `numpy.array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568732a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a81532cb56dee54d3de1ed713559d194",
     "grade": false,
     "grade_id": "cell-7b3cedcad4ebac39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_gradient_descent_ls(objective_function, gradient_function, f0, n):\n",
    "    \"\"\" \n",
    "    :param objective_function: objective function of f.\n",
    "    :param gradient_function: gradient of the objective function of f.\n",
    "    :param f0: Starting values for initializing the parameters f.\n",
    "    :param n: Number of iterative gradient updates.\n",
    "    :returns: Final f and an array of n + 1 objective values in the optimization history.\n",
    "    \"\"\"\n",
    "    f = f0\n",
    "    objective_values = [objective_function(f)]\n",
    "    for i in range(n+1):\n",
    "        s = lambda x: objective_function(f - x*gradient_function(f))\n",
    "        s_min = fminbound(s, 0, 10)\n",
    "        f = f - s_min * gradient_function(f)\n",
    "        objective_values.append(objective_function(f))\n",
    "    return f, np.array(objective_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d19d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1baebacf27f7ec8062e56282f5574280",
     "grade": true,
     "grade_id": "a020",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7c3a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f70b08d43eaa1febab08e29498daa515",
     "grade": true,
     "grade_id": "a030",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29298f43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0294355bc7f7eb3f2905121d0775dedd",
     "grade": false,
     "grade_id": "cell-f9f10f652172ac76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tikhonov regularization with gradient descent \n",
    "Implement the gradient of the objective function with Tikhonov regularization\n",
    "$$\n",
    "\\nabla L(f) = 2 A^T (Af - g') + 2 \\lambda D'^T D'f\n",
    "$$\n",
    "* Given the input signal $f$\n",
    "* Given the system matrix $A$\n",
    "* Given the measurement $g'$\n",
    "* Given the regularization matrix $D'$\n",
    "* Given the regularization parameter $\\lambda$\n",
    "* Implement the function `gradient_tikhonov()` (using `numpy.array`)\n",
    "\n",
    "The gradient magnitude solution is the solution with $D' = D_\\text{diff}$\n",
    "* Calculate the solution by gradient descent for the noisy signals in `list_gn`\n",
    "* Return the outputs with $\\lambda$ of $0.1$, $0.01$, $0.001$, respectively, with $f^{(0)}=0$, $n=20$\n",
    "* Save the solutions in the variable `list_f_gd` (as `list` of `numpy.array`)\n",
    "* Save the corresponding objective value history in the variable `list_L_gd` (as `list` of `numpy.array`)\n",
    "\n",
    "Display the result\n",
    "* Plot the outputs in `list_f_gd` in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplot column\n",
    "* Show the cases with the same $\\lambda$ in the same subplot row\n",
    "* Plot the corresponding noisy signal in each subplot\n",
    "* Plot the input signal `f_true` in each subplot\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "* Show the objective function value of each output in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76380966",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d336133471c0ce50c461fb92922e83a8",
     "grade": true,
     "grade_id": "a040",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_tikhonov(f, A, g, D, lb):\n",
    "    \"\"\" Compute the gradient of the objective function with Tikhonov regularization.\n",
    "    \n",
    "    :param f: Current estimate of the signal.\n",
    "    :param A: 2D matrix of the linear problem.\n",
    "    :param g: Observed signal.\n",
    "    :param D: 2D matrix in the regularization term.\n",
    "    :param lb: Regularization parameter.\n",
    "    :returns: Gradient value of the objective function.\n",
    "    \"\"\"\n",
    "    return 2 * A.T @ (A @ f - g) + 2 * lb  * D.T @ D @ f\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Gradient magnitude solution (gradient descent)')\n",
    "\n",
    "lbs = [0.1, 0.01, 0.001]\n",
    "f0 = np.zeros(f_true.shape)\n",
    "n = 20\n",
    "\n",
    "list_f_gd = []\n",
    "list_L_gd = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        objective = lambda x: objective_tikhonov(x, A_psf, list_gn[j], get_diff_matrix(A_psf.shape[0]), lbs[i])\n",
    "        grad = lambda x: gradient_tikhonov(x, A_psf, list_gn[j], get_diff_matrix(A_psf.shape[0]), lbs[i])\n",
    "\n",
    "        f_gd, L_gd = solve_gradient_descent_ls(objective, grad, f0, n)\n",
    "\n",
    "        MSE = int(mean_squared_error(f_gd, f_true))\n",
    "\n",
    "        axs[i,j].plot(f_gd, label=\"$f_{est}$\", color=\"black\")\n",
    "        axs[i,j].plot(list_gn[j], label=\"g\")\n",
    "        axs[i,j].plot(f_true, label=\"$f_{true}$\")\n",
    "        \n",
    "        axs[i,j].set_title(\"$g_{}$, $\\lambda={}$, MSE={}, $L(f)={}$\".format(j, lbs[i], MSE, int(L_gd[-1])))\n",
    "        axs[i,j].legend()\n",
    "\n",
    "        list_f_gd.append(f_gd)\n",
    "        list_L_gd.append(L_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa0a6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d91713b20fab801894a96355449410",
     "grade": true,
     "grade_id": "a050",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c825af4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b9818f10df762b34b6998364caa5797",
     "grade": false,
     "grade_id": "cell-502917623115bdcd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Optimization history\n",
    "Display the result\n",
    "* Plot the arrays in `list_L_gd` as solid lines in the same order of the parameter options in the subplots of `axs`\n",
    "* Plot the values in `list_L_closed` as horizontal dash lines in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplots\n",
    "* Make the subplots with log scaling on the y axis\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "* Show the objective function value of each output in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974101e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc85125983299f03286dd912d545a044",
     "grade": true,
     "grade_id": "a060",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Gradient magnitude solution (gradient descent)')\n",
    "fig.subplots_adjust(top=0.7)\n",
    "colors = [\"blue\", \"orange\", \"green\"]\n",
    "title = [\"$g_{0}$\", \"$g_{1}$\", \"$g_{2}$\"]\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[j].plot(list_L_gd[i*3+j], label=\" $\\lambda={}$\".format(lbs[i])) \n",
    "        axs[j].hlines(list_L_closed[i*3+j], 0, len(list_L_gd[0]), label=\"$\\lambda={}$\".format(lbs[i]), linestyle=\"--\", color=colors[i])\n",
    "        MSE = int(mean_squared_error(list_f_gd, f_true))\n",
    "\n",
    "        title[j] = title[j] + f\"\\n$\\lambda$={lbs[i]}: mse={MSE:.1f}, obj={list_L_gd[i*3+j][-1]:.1f}\"\n",
    "        axs[j].set_title(title[j])\n",
    "        axs[j].set_yscale(\"log\")\n",
    "        axs[j].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-roommate",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2a88d3a008128bc45c4d11a056fc99a",
     "grade": false,
     "grade_id": "cell-65ba46540d29d67f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Total variation\n",
    "The objective function with total variation is\n",
    "$$\n",
    "L(f) = \\|Af - g\\|_2^2 + \\lambda\\|\\nabla f\\|_1\n",
    "$$\n",
    "The gradient of the objective function with total variation is\n",
    "$$\n",
    "\\nabla L(f) \n",
    "\\approx 2 A^T (Af - g) + \\lambda \\nabla \\sum_{j=1}^{n} \\sqrt{(f_j - f_{j-1})^2 + \\beta^2}\n",
    "= 2 A^T (Af - g) + \\lambda \\begin{bmatrix} \n",
    "r_1 \\\\\n",
    "... \\\\\n",
    "r_i \\\\\n",
    "... \\\\\n",
    "r_n \\end{bmatrix},\n",
    "$$\n",
    "where $1 \\gg \\beta^2 > 0$ and\n",
    "$$\n",
    "r_i = \\frac{f_i - f_{i-1}}{\\sqrt{(f_i - f_{i-1})^2 + \\beta^2}}\n",
    "- \\frac{f_{i+1} - f_{i}}{\\sqrt{(f_{i+1} - f_{i})^2 + \\beta^2}}\n",
    "$$\n",
    "with $f_{-1} = 0$ and $f_{n} = 0$.\n",
    "\n",
    "* Given the input signal $f$\n",
    "* Given the system matrix $A$\n",
    "* Given the measurement $g'$\n",
    "* Given the regularization parameter $\\lambda$\n",
    "* Implement the objective function `objective_tv()` (using `numpy.array`)\n",
    "* Implement the gradient of the objective function with $\\beta^2 = 0.001$ `gradient_tv()` (using `numpy.array`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e0812",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87497a1a07fa2bcf52be27b6cd0421f2",
     "grade": false,
     "grade_id": "cell-7306796d97c96cb7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def objective_tv(f, A, g, lb):\n",
    "    \"\"\" \n",
    "    :param f: Current estimate of the signal.\n",
    "    :param A: 2d Matrix A of the linear problem.\n",
    "    :param g: Observed signal.\n",
    "    :param lb: Regularization strength of TV.\n",
    "    :returns: Objective function value.\n",
    "    \"\"\"\n",
    "    return np.sum((A@f - g)**2) + lb * np.sum(np.abs(get_diff_matrix(f.shape[0]) @ f))\n",
    "\n",
    "def gradient_tv(f, A, g, lb):\n",
    "    \"\"\" \n",
    "    :param f: Current estimate of the signal.\n",
    "    :param A: 2d Matrix A of the linear problem.\n",
    "    :param g: Observed signal.\n",
    "    :param lb: Regularization strength of TV.\n",
    "    :returns: Gradient value of the objective function.\n",
    "    \"\"\"\n",
    "    beta = 0.001\n",
    "    r = np.zeros(f.shape)\n",
    "    f_pad = np.pad(f, 1)\n",
    "    \n",
    "    for i in range(1, f.shape[0]):\n",
    "        r[i-1] = (f_pad[i] - f_pad[i-1]) / np.sqrt((f_pad[i]-f_pad[i-1])**2+beta**2) - (f_pad[i+1] - f_pad[i]) / np.sqrt((f_pad[i+1]-f_pad[i])**2+beta**2)\n",
    "    \n",
    "    return 2*A.T@(A @ f - g) + lb * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff05ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af94847e461b67c7155caa135f29a27b",
     "grade": true,
     "grade_id": "a070",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee484e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1342b323008913a2157a3f7abb10f29b",
     "grade": false,
     "grade_id": "cell-fe246c0b24bd8a20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Total variation with gradient descent \n",
    "Solve the objective function with total variation by gradient descent \n",
    "* Calculate the solution by gradient descent for the noisy signals in `list_gn`\n",
    "* Return the outputs with $\\lambda$ of $0.1$, $0.01$, $0.001$, respectively, with $f^{(0)}=0$, $n=20$\n",
    "* Save the solutions in the variable `list_f_tv` (as `list` of `numpy.array`)\n",
    "* Save the corresponding objective value history in the variable `list_L_tv` (as `list` of `numpy.array`)\n",
    "\n",
    "Display the result\n",
    "* Plot the outputs in `list_f_tv` in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplot column\n",
    "* Show the cases with the same $\\lambda$ in the same subplot row\n",
    "* Plot the corresponding noisy signal in each subplot\n",
    "* Plot the input signal `f_true` in each subplot\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "* Show the objective function value of each output in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ab5ae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c41346bb5e65e65f9c450ebd2d0e4de",
     "grade": true,
     "grade_id": "a080",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Total variation solution (gradient descent)')\n",
    "\n",
    "lbs = [0.1, 0.01, 0.001]\n",
    "f0 = np.zeros(f_true.shape)\n",
    "n = 20\n",
    "\n",
    "list_f_tv = []\n",
    "list_L_tv = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        objective = lambda x: objective_tv(x, A_psf, list_gn[j], lbs[i])\n",
    "        grad = lambda x: gradient_tv(x, A_psf, list_gn[j], lbs[i])\n",
    "\n",
    "        f_tv, L_tv = solve_gradient_descent_ls(objective, grad, f0, n)\n",
    "\n",
    "        MSE = int(mean_squared_error(f_tv, f_true))\n",
    "        \n",
    "        axs[i,j].plot(f_tv, label=\"$f_{est}$\")\n",
    "        axs[i,j].plot(list_gn[j], label=\"g\")\n",
    "        axs[i,j].plot(f_true, color=\"black\", label=\"$f_{true}$\")\n",
    "        \n",
    "        axs[i,j].set_title(\"$g_{}$, $\\lambda={}$, MSE={}, $L(f)={}$\".format(j, lbs[i], MSE, int(L_tv[-1])))\n",
    "        axs[i,j].legend()\n",
    "\n",
    "        list_f_tv.append(f_tv)\n",
    "        list_L_tv.append(L_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f287b8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8774e75ea2d4b29915c36240ad92936",
     "grade": true,
     "grade_id": "a090",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains hidden tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d2df7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b19fdc3eb8f6a8351bda1f1b8c79f43b",
     "grade": false,
     "grade_id": "cell-2ad6030d559e9546",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Optimization history\n",
    "Display the result\n",
    "* Plot the arrays in `list_L_tv` as solid lines in the same order of the parameter options in the subplots of `axs`\n",
    "* Show the cases of the same noisy signal in the same subplots\n",
    "* Make the subplots with log scaling on the y axis\n",
    "* Show the legend in each subplot\n",
    "* Show the case information in the titles to the subplots\n",
    "* Show the mean squared error of each output comparing to `f_true` in the titles to the subplots\n",
    "* Show the objective function value of each output in the titles to the subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e1871",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09a9ea48ad5145e9b023937533234064",
     "grade": true,
     "grade_id": "a100",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Total variation solution (gradient descent)')\n",
    "fig.subplots_adjust(top=0.7)\n",
    "\n",
    "title = [\"$g_{0}$\", \"$g_{1}$\", \"$g_{2}$\"]\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        MSE = int(mean_squared_error(list_f_gd[i*3+j], f_true))\n",
    "        axs[j].plot(list_L_tv[i*3+j], label=\"$\\lambda={}$\".format(lbs[i]))\n",
    "        title[j] = title[j] + f\"\\n$\\lambda$={lbs[i]}: mse={MSE:.1f}, obj={list_L_tv[i*3+j][-1]:.1f}\"\n",
    "        axs[j].set_title(title[j])\n",
    "        axs[j].set_yscale(\"log\")\n",
    "        axs[j].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "201f1b4038dffb4c6751655281afe604dea13cfaed561b9843a99ea909229d43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
